{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval2019 Hyperpartisan News Detection\n",
    "#### Extract features derived from sentiment and bias lexicons, and writing style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml.etree import iterparse\n",
    "import xml\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from utils import *\n",
    "from text_featurizer import *\n",
    "from readability import Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFiles(textFile, labelFile):\n",
    "    X,y = [], []\n",
    "    \n",
    "    with open(labelFile) as labelFile:\n",
    "        xml.sax.parse(labelFile, GroundTruthHandler(y))\n",
    "       \n",
    "    for event, elem in iterparse(textFile):\n",
    "        if elem.tag == \"article\":\n",
    "            title = elem.attrib['title']\n",
    "            text = \"\".join(elem.itertext())\n",
    "            text = textCleaning(title, text) \n",
    "            X.append(text)\n",
    "            elem.clear()\n",
    "            \n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set path for data\n",
    "dataPath = 'data/'\n",
    "textFile = dataPath + 'articles-training-byarticle.xml'\n",
    "labelFile = dataPath + \"ground-truth-training-byarticle.xml\"\n",
    "\n",
    "texts, labels = readFiles(textFile, labelFile)\n",
    "\n",
    "# split the samples with the same seed to compare results with other methods\n",
    "id1, id2 = fixedTestSplit(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def switcher(pos):\n",
    "    '''\n",
    "    Map POS tags to coarse categories\n",
    "    '''\n",
    "    pos_family = {'NN': 'noun', 'NNS': 'noun', 'NNP': 'noun', 'NNPS': 'noun',\n",
    "    'VB': 'verb', 'VBD': 'verb', 'VBG': 'verb', 'VBN': 'verb', 'VBP': 'verb', 'VBZ': 'verb',\n",
    "    'JJ': 'adj', 'JJR': 'adj', 'JJS': 'adj',\n",
    "    'PRP': 'pron', 'PRP$': 'pron', 'WP': 'pron', 'WP$': 'pron',\n",
    "    'RB': 'adverb', 'RBR': 'adverb', 'RBS': 'adverb'}\n",
    "\n",
    "    if pos in pos_family.keys():\n",
    "        return pos_family[pos]\n",
    "    else:\n",
    "        return 'others'\n",
    "    \n",
    "def extractPOS(pos_tags):\n",
    "    '''\n",
    "    Extract normalized POS counts\n",
    "    '''\n",
    "    pos_dict = collections.OrderedDict({'noun':0, 'verb':0, 'adj':0, 'pron':0, 'adverb':0, 'others':0})\n",
    "    for t in pos_tags:\n",
    "        pos = switcher(t[1])\n",
    "        pos_dict[pos] = pos_dict[pos] + 1\n",
    "    \n",
    "    feat = [val/len(pos_tags) for i,val in pos_dict.items() if i is not 'other']\n",
    "        \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractReadabilityScores(text):\n",
    "    rd = Readability(text)\n",
    "    return [rd.ARI(), rd.FleschReadingEase(), rd.ColemanLiauIndex(), rd.FleschKincaidGradeLevel(), rd.LIX(), rd.RIX()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textVectorize(texts):\n",
    "    '''\n",
    "    Extract features: # quotations, POS tags count, bias word counts, sentiment word counts, subjective word counts\n",
    "    readability scores, and writing styles. \n",
    "    '''\n",
    "    features = []\n",
    "    for text in texts:\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        pos_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        words = [t.lower() for t in tokens if t.isalpha()]\n",
    "    \n",
    "        quotation = len(re.findall('\"', text))\n",
    "        text_feats = extract_text_features(sentences, words)    \n",
    "        pos_feats = extractPOS(pos_tags)\n",
    "        bias_feat = bias_lexicon(words)\n",
    "        sub_feat = subjective_lexicon(pos_tags)\n",
    "        sent_feats = mpqa_sentiment(words)\n",
    "        read = extractReadabilityScores(text)\n",
    "        feat = [text_feats, pos_feats, bias_feat, sub_feat, sent_feats, [quotation], read]\n",
    "        flattened = [val for sublist in feat for val in sublist]\n",
    "        \n",
    "        features.append(flattened)\n",
    "    return np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = textVectorize(texts)\n",
    "# delete features that are not representated\n",
    "delete = np.where(np.sum(features, 0) == 0)[0]\n",
    "feat_select = np.delete(features, delete,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the features to be appended to other features\n",
    "np.save(\"features\", feat_select)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
